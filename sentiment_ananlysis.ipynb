{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2062ecae-d3a2-4967-b49f-dbe5e9d33284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ec38d07-8111-4719-82c2-8a48799318c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_data = pd.read_csv(\"clean_data_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a22f8d-a031-4014-bb64-afe4f756d068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>is_Extrovert</th>\n",
       "      <th>is_Sensing</th>\n",
       "      <th>is_Thinking</th>\n",
       "      <th>is_Judging</th>\n",
       "      <th>posts</th>\n",
       "      <th>clean_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'When asked of the things you wish you did ear...</td>\n",
       "      <td>'when asked thing wish earlier (' ), find answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'I love both and they are equally important to...</td>\n",
       "      <td>' love equally important . music window soul. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Really? You think implying that everyone who i...</td>\n",
       "      <td>really? think implying everyone entrepreneur s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'Love is a crazy thing.   Se is our best form ...</td>\n",
       "      <td>'love crazy thing.    best form communication,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INTP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>'I am a physics undergrad with a computation e...</td>\n",
       "      <td>' physic undergrad computation emphasis, /will...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  is_Extrovert  is_Sensing  is_Thinking  is_Judging  \\\n",
       "0  INFJ             0           0            0           1   \n",
       "1  INFJ             0           0            0           1   \n",
       "2  INFJ             0           0            0           1   \n",
       "3  ENFJ             1           0            0           1   \n",
       "4  INTP             0           0            1           0   \n",
       "\n",
       "                                               posts  \\\n",
       "0  'When asked of the things you wish you did ear...   \n",
       "1  'I love both and they are equally important to...   \n",
       "2  Really? You think implying that everyone who i...   \n",
       "3  'Love is a crazy thing.   Se is our best form ...   \n",
       "4  'I am a physics undergrad with a computation e...   \n",
       "\n",
       "                                         clean_posts  \n",
       "0  'when asked thing wish earlier (' ), find answ...  \n",
       "1  ' love equally important . music window soul. ...  \n",
       "2  really? think implying everyone entrepreneur s...  \n",
       "3  'love crazy thing.    best form communication,...  \n",
       "4  ' physic undergrad computation emphasis, /will...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33545e07-211f-417e-a73d-ae880debb324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8588, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f73a9e1-d137-4271-b107-782d2146e9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type            0\n",
       "is_Extrovert    0\n",
       "is_Sensing      0\n",
       "is_Thinking     0\n",
       "is_Judging      0\n",
       "posts           0\n",
       "clean_posts     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c1af62-e89a-4f6a-ab0a-0820afb8a335",
   "metadata": {},
   "source": [
    "# Setiment Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43fff3fd-3992-42f5-a60c-c07171724070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Scoring Time: 162.23 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "nlp_sentiment_score = []\n",
    "for post in personality_data[\"clean_posts\"]:\n",
    "    score = analyzer.polarity_scores(post)\n",
    "    nlp_sentiment_score.append(score)\n",
    "print(f\"Sentiment Scoring Time: {time.time() - t:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef0208e-824f-4dce-8a8d-7352ef40f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segregating the indiviual sentiment scores - compound, positive, negative and neutral\n",
    "personality_data[\"compound_sentiment\"] = [\n",
    "    score[\"compound\"] for score in nlp_sentiment_score\n",
    "]\n",
    "personality_data[\"pos_sentiment\"] = [score[\"pos\"] for score in nlp_sentiment_score]\n",
    "personality_data[\"neg_sentiment\"] = [score[\"neg\"] for score in nlp_sentiment_score]\n",
    "personality_data[\"neu_sentiment\"] = [score[\"neu\"] for score in nlp_sentiment_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98867ddd-2a1f-45f4-a060-09e51311e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment scores have negative values that Naive Bayes can't handle. So scaling it.\n",
    "min_max_scaler = MinMaxScaler()\n",
    "personality_data[\"compound_sentiment\"] = min_max_scaler.fit_transform(\n",
    "    np.array(personality_data[\"compound_sentiment\"]).reshape(-1, 1)\n",
    ")\n",
    "personality_data[\"pos_sentiment\"] = min_max_scaler.fit_transform(\n",
    "    np.array(personality_data[\"pos_sentiment\"]).reshape(-1, 1)\n",
    ")\n",
    "personality_data[\"neg_sentiment\"] = min_max_scaler.fit_transform(\n",
    "    np.array(personality_data[\"neg_sentiment\"]).reshape(-1, 1)\n",
    ")\n",
    "personality_data[\"neu_sentiment\"] = min_max_scaler.fit_transform(\n",
    "    np.array(personality_data[\"neu_sentiment\"]).reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b5d8af8-d2a2-455d-ad77-b9db1c3e2ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type                  0\n",
       "is_Extrovert          0\n",
       "is_Sensing            0\n",
       "is_Thinking           0\n",
       "is_Judging            0\n",
       "posts                 0\n",
       "clean_posts           0\n",
       "compound_sentiment    0\n",
       "pos_sentiment         0\n",
       "neg_sentiment         0\n",
       "neu_sentiment         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if sentiment scores introduced any null value\n",
    "personality_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e38fe3-5306-491d-8a16-65d4c8c1b6a4",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb976d90-145e-4c0b-8c7e-aa38e311c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_data[\"tag_posts\"] = personality_data[\"posts\"].str.replace(\n",
    "    re.compile(r\"https?:\\/\\/(www\\.)?([A-Za-z_0-9-]+)([\\S])*\"),\n",
    "    lambda match: match.group(2),\n",
    "    regex=True\n",
    ")\n",
    "personality_data[\"tag_posts\"] = personality_data[\"tag_posts\"].str.split(\"|||\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ecb1e6a-9012-4eaa-9471-9b928d46b501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import time\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')  # Ensure the tokenizer models are also downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b8b5c24-62ef-4302-8197-a91509e58800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tagging Time: 12263.069110631943 seconds\n"
     ]
    }
   ],
   "source": [
    "# parts of speech tagging for each word\n",
    "t = time.time()\n",
    "\n",
    "personality_data[\"tagged_words\"] = personality_data[\"tag_posts\"].apply(\n",
    "    lambda x: [nltk.pos_tag(word_tokenize(line)) for line in x]\n",
    ")\n",
    "\n",
    "print(f\"POS Tagging Time: {time.time() - t} seconds\")\n",
    "#Takes a lot of time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69b052c2-49a8-4f8b-a649-af5a1951f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_set = set()\n",
    "\n",
    "for i, data in personality_data[\"tagged_words\"].items():\n",
    "    for tup in data[0]:\n",
    "        tag_set.add(tup[1])\n",
    "\n",
    "tag_list = list(tag_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c80fb502-6a55-4233-923c-b6fd077a7703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Stats Time: 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# calculating mean and standard deviation of pos tags for each user\n",
    "t = time.time()\n",
    "\n",
    "\n",
    "def pos_cat(x, tag):\n",
    "    return [len([y for y in line if y[1] == tag]) for line in x]\n",
    "\n",
    "\n",
    "for col in tag_list:\n",
    "    personality_data[\"POS_\" + col + \"_mean\"] = personality_data[\"tagged_words\"].apply(\n",
    "        lambda x: np.mean(pos_cat(x, col))\n",
    "    )\n",
    "    personality_data[\"POS_\" + col + \"_std\"] = personality_data[\"tagged_words\"].apply(\n",
    "        lambda x: np.std(pos_cat(x, col))\n",
    "    )\n",
    "\n",
    "print(f\"POS Stats Time: {time.time() - t} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41e6879c-bc44-4b9b-b1fe-7a7bc1c754bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping pos tags based on stanford list\n",
    "tags_dict = {\n",
    "    \"ADJ\": [\"JJ\", \"JJR\", \"JJS\"],\n",
    "    \"ADP\": [\"EX\", \"TO\"],\n",
    "    \"ADV\": [\"RB\", \"RBR\", \"RBS\", \"WRB\"],\n",
    "    \"CONJ\": [\"CC\", \"IN\"],\n",
    "    \"DET\": [\"DT\", \"PDT\", \"WDT\"],\n",
    "    \"NOUN\": [\"NN\", \"NNS\", \"NNP\", \"NNPS\"],\n",
    "    \"NUM\": [\"CD\"],\n",
    "    \"PRT\": [\"RP\"],\n",
    "    \"PRON\": [\"PRP\", \"PRP$\", \"WP\", \"WP$\"],\n",
    "    \"VERB\": [\"MD\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"],\n",
    "    \".\": [\"#\", \"$\", \"''\", \"(\", \")\", \",\", \".\", \":\"],\n",
    "    \"X\": [\"FW\", \"LS\", \"UH\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efb3f968-40d1-46e8-92bc-ee113d929a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanford POS Stats Time: 207.9080319404602 seconds\n"
     ]
    }
   ],
   "source": [
    "# Stanford POS tag stats\n",
    "t = time.time()\n",
    "\n",
    "\n",
    "def stanford_tag(x, tag):\n",
    "    tags_list = [len([y for y in line if y[1] in tags_dict[col]]) for line in x]\n",
    "    return tags_list\n",
    "\n",
    "\n",
    "for col in tags_dict.keys():\n",
    "    personality_data[col + \"_avg\"] = personality_data[\"tagged_words\"].apply(\n",
    "        lambda x: np.median(stanford_tag(x, col))\n",
    "    )\n",
    "\n",
    "print(f\"Stanford POS Stats Time: {time.time() - t} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "264e75b8-da45-4d22-aa0b-3a26ba3d4d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>is_Extrovert</th>\n",
       "      <th>is_Sensing</th>\n",
       "      <th>is_Thinking</th>\n",
       "      <th>is_Judging</th>\n",
       "      <th>posts</th>\n",
       "      <th>clean_posts</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>ADV_avg</th>\n",
       "      <th>CONJ_avg</th>\n",
       "      <th>DET_avg</th>\n",
       "      <th>NOUN_avg</th>\n",
       "      <th>NUM_avg</th>\n",
       "      <th>PRT_avg</th>\n",
       "      <th>PRON_avg</th>\n",
       "      <th>VERB_avg</th>\n",
       "      <th>._avg</th>\n",
       "      <th>X_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'When asked of the things you wish you did ear...</td>\n",
       "      <td>'when asked thing wish earlier (' ), find answ...</td>\n",
       "      <td>0.99985</td>\n",
       "      <td>0.530909</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>'I love both and they are equally important to...</td>\n",
       "      <td>' love equally important . music window soul. ...</td>\n",
       "      <td>0.99995</td>\n",
       "      <td>0.747273</td>\n",
       "      <td>0.222535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  is_Extrovert  is_Sensing  is_Thinking  is_Judging  \\\n",
       "0  INFJ             0           0            0           1   \n",
       "1  INFJ             0           0            0           1   \n",
       "\n",
       "                                               posts  \\\n",
       "0  'When asked of the things you wish you did ear...   \n",
       "1  'I love both and they are equally important to...   \n",
       "\n",
       "                                         clean_posts  compound_sentiment  \\\n",
       "0  'when asked thing wish earlier (' ), find answ...             0.99985   \n",
       "1  ' love equally important . music window soul. ...             0.99995   \n",
       "\n",
       "   pos_sentiment  neg_sentiment  ...  ADV_avg CONJ_avg DET_avg  NOUN_avg  \\\n",
       "0       0.530909       0.211268  ...      0.0      0.0     0.0       1.0   \n",
       "1       0.747273       0.222535  ...      0.0      0.0     0.0       1.0   \n",
       "\n",
       "   NUM_avg  PRT_avg  PRON_avg  VERB_avg  ._avg  X_avg  \n",
       "0      0.0      0.0       0.0       0.0    0.0    0.0  \n",
       "1      0.0      0.0       0.0       0.0    0.0    0.0  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personality_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b8390ec-c814-474f-bd94-81fa92c7fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_data.to_csv((\"clean_data_2.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
